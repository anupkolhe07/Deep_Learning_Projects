{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b>The MNIST dataset consists of a collection of 28x28 pixel grayscale images of handwritten digits (0 through 9). Each image is labeled with the corresponding digit it represents. For example, an image might depict the handwritten digit \"7\", and its corresponding label would be \"7\".\n",
        "\n",
        "<font color  = \"red\"><b>Problem Statement:\n",
        "\n",
        "Given a set of these handwritten digit images and their corresponding labels, the task is to develop a machine learning or deep learning model that can accurately classify unseen handwritten digits into their respective categories (0 through 9).The goal is to train a model that can generalize well to classify digits it hasn't seen before with high accuracy."
      ],
      "metadata": {
        "id": "WX9dzouNZZ32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4w6paDsYZBxb"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for numerical operations\n",
        "import numpy as np\n",
        "\n",
        "# Import TensorFlow and Keras for deep learning functionalities\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "# Import specific modules from Keras for defining neural network layers and models\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Import function for splitting data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import OneHotEncoder for encoding categorical labels into one-hot vectors\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset from the Keras datasets module\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Load the training and testing data along with their respective labels\n",
        "# The dataset is divided into training and testing sets, where x_train and x_test contain the images,\n",
        "# and y_train and y_test contain the corresponding labels\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfX49vRGZReW",
        "outputId": "15bd71ec-488c-40f5-e840-132621b6f64d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Let us check the dataset"
      ],
      "metadata": {
        "id": "Hjc1VgK-aYjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYo51msaZ7_j",
        "outputId": "6cef2aec-8fce-4927-9270-90b13929d22a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51zxeOplacOY",
        "outputId": "87cd7345-5d3f-4a60-c1bd-0675650f08ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> <font color=\"black\">Checking the shape of the data"
      ],
      "metadata": {
        "id": "Oyff8RlWbFgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai17r4vFafhP",
        "outputId": "15a23d4a-11d8-4bac-8d2e-d07feeaca42b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQGNOar3atUU",
        "outputId": "2eedde5a-fa09-4846-9abc-dfbc54619bc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITO_lM9kaxCV",
        "outputId": "9efce70f-f959-48f0-cead-27019f7ad7c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTRPJkBKbLNO",
        "outputId": "c0b8aad8-0e65-4c25-baa3-eda0ea969c1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the training and testing images by dividing each pixel value by 255.0\n",
        "# This scales the pixel values to be in the range between 0 and 1, which is beneficial for training neural networks\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "lzWix8Bcaz9Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the training and testing images from 28x28 arrays to flattened vectors\n",
        "# This flattening process converts each 28x28 image into a 1-dimensional array of length 784 (28*28)\n",
        "# It reshapes the data to be compatible with the input layer of a neural network\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "CqAq2MwJcXfJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shapes of train and test data\n",
        "print(x_train_flat.shape)\n",
        "print(x_test_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FTkSr6ZeDNx",
        "outputId": "24769492-9d3e-4bb1-e2b9-7e904c4d5f8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform one-hot encoding on the training and testing labels\n",
        "# One-hot encoding converts categorical labels (digits 0 through 9) into binary vectors\n",
        "# Each binary vector has a length equal to the number of classes (10 in this case), with a 1 at the index corresponding to the class and 0s elsewhere\n",
        "# This transformation is necessary for training a neural network, as it enables the network to predict multiple classes simultaneously\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_onehot = onehot_encoder.transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "2J5SQwqQeNJf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"One-hot encoded y_train shape:\", y_train_onehot.shape)\n",
        "print(\"One-hot encoded y_test shape:\", y_test_onehot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQgWUSUiY5S",
        "outputId": "4ff017fb-a703-4399-9068-af0373c9c349"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded y_train shape: (60000, 10)\n",
            "One-hot encoded y_test shape: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture of the Artificial Neural Network (ANN) model using the Sequential API\n",
        "# The Sequential API allows you to create a linear stack of layers for building the neural network model\n",
        "\n",
        "model = models.Sequential([\n",
        "    # Add a fully connected (dense) layer with 128 units\n",
        "    # The 'relu' activation function is used to introduce non-linearity into the network\n",
        "    # The input shape is specified as (784,), corresponding to the flattened input images\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "\n",
        "    # Add a dropout layer with a dropout rate of 0.2\n",
        "    # Dropout is a regularization technique used to prevent overfitting by randomly dropping a fraction of the input units during training\n",
        "    # A dropout rate of 0.2 means that 20% of the input units will be randomly set to 0 during each training iteration\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Add another fully connected (dense) layer with 10 units\n",
        "    # The 'softmax' activation function is used to convert the raw outputs into probability scores for each class\n",
        "    # Softmax ensures that the output probabilities sum up to 1, making it suitable for multi-class classification problems\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "qEI2Kw9pi-lw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the neural network model with specified optimizer, loss function, and evaluation metrics\n",
        "\n",
        "# Optimizer: 'adam'\n",
        "# Adam is an adaptive learning rate optimization algorithm that combines the benefits of both AdaGrad and RMSProp\n",
        "# It dynamically adjusts the learning rate during training, making it well-suited for a wide range of problems\n",
        "# The 'adam' optimizer is commonly used for training neural networks due to its efficiency and effectiveness\n",
        "\n",
        "# Loss Function: 'categorical_crossentropy'\n",
        "# Categorical Crossentropy is a common loss function used for multi-class classification problems with one-hot encoded labels\n",
        "# It calculates the difference between the predicted probability distribution and the true probability distribution\n",
        "# The goal is to minimize this difference, effectively training the model to predict the correct class with high confidence\n",
        "\n",
        "# Metrics: [\"accuracy\"]\n",
        "# The accuracy metric is used to evaluate the performance of the model during training and testing\n",
        "# It measures the proportion of correctly classified samples over the total number of samples\n",
        "# Maximizing accuracy is typically the primary goal when training classification models\n",
        "\n",
        "model.compile(optimizer=\"adam\",   # Specify the optimizer as 'adam'\n",
        "              loss='categorical_crossentropy',   # Use 'categorical_crossentropy' as the loss function\n",
        "              metrics=[\"accuracy\"])   # Evaluate the model's performance using accuracy as the metric\n"
      ],
      "metadata": {
        "id": "J6spbWAgjv0L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into training and test\n",
        "x_train_split, x_val, y_train_split, y_val=train_test_split(x_train_flat, y_train_onehot, test_size=0.2, random_state=5)"
      ],
      "metadata": {
        "id": "vE61IG90nMSo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the neural network model on the training data\n",
        "\n",
        "# Training Data: (x_train_split, y_train_split)\n",
        "# x_train_split: Training images after splitting from the original training data\n",
        "# y_train_split: Corresponding one-hot encoded labels for the training images\n",
        "\n",
        "# Validation Data: (x_val, y_val)\n",
        "# x_val: Validation images used to monitor the performance of the model during training\n",
        "# y_val: Corresponding one-hot encoded labels for the validation images\n",
        "\n",
        "# Epochs: 10\n",
        "# An epoch refers to one complete pass through the entire training dataset during training\n",
        "# Training the model for multiple epochs allows it to learn from the data and improve its performance gradually\n",
        "# Here, the model will be trained for 10 epochs\n",
        "\n",
        "# Batch Size: 128\n",
        "# Batch size refers to the number of samples processed before the model's parameters are updated during training\n",
        "# Using a batch size of 128 means that the training data will be divided into batches of 128 samples each\n",
        "# The model's parameters will be updated based on the average loss calculated over each batch\n",
        "\n",
        "# Training Procedure:\n",
        "# During training, the model will learn to minimize the specified loss function (categorical crossentropy) using the 'adam' optimizer\n",
        "# The performance of the model will be evaluated on both the training and validation datasets using the accuracy metric\n",
        "\n",
        "img_model = model.fit(x_train_split,   # Training images\n",
        "                      y_train_split,   # Training labels\n",
        "                      epochs=10,   # Number of training epochs\n",
        "                      batch_size=128,   # Batch size\n",
        "                      validation_data=(x_val, y_val))   # Validation data for monitoring performance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvImpsJ7pgeB",
        "outputId": "eeffcef7-34a1-4d31-b892-9529b21806e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 9ms/step - loss: 0.4443 - accuracy: 0.8736 - val_loss: 0.2263 - val_accuracy: 0.9383\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.2146 - accuracy: 0.9381 - val_loss: 0.1644 - val_accuracy: 0.9548\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1600 - accuracy: 0.9528 - val_loss: 0.1314 - val_accuracy: 0.9607\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1328 - accuracy: 0.9613 - val_loss: 0.1129 - val_accuracy: 0.9685\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1133 - accuracy: 0.9667 - val_loss: 0.1052 - val_accuracy: 0.9704\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0978 - accuracy: 0.9708 - val_loss: 0.0988 - val_accuracy: 0.9711\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0863 - accuracy: 0.9745 - val_loss: 0.0900 - val_accuracy: 0.9743\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0779 - accuracy: 0.9761 - val_loss: 0.0874 - val_accuracy: 0.9746\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0694 - accuracy: 0.9785 - val_loss: 0.0851 - val_accuracy: 0.9747\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0639 - accuracy: 0.9806 - val_loss: 0.0831 - val_accuracy: 0.9764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the trained model on the testing data to assess its performance\n",
        "\n",
        "# Testing Data: (x_test_flat, y_test_onehot)\n",
        "# x_test_flat: Flattened testing images after normalization\n",
        "# y_test_onehot: One-hot encoded labels for the testing images\n",
        "\n",
        "# The 'evaluate' method computes the loss value and metrics (accuracy in this case) for the testing data\n",
        "test_loss, test_accuracy = model.evaluate(x_test_flat, y_test_onehot)\n",
        "\n",
        "# Print the test loss and test accuracy\n",
        "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bCX03y1qIGl",
        "outputId": "a7af9487-8b5a-44b1-ef00-4e74be67f197"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9766\n",
            "Test loss: 0.07770629972219467, Test accuracy: 0.9765999913215637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color = Green><b> Results\n",
        "\n",
        "The results of evaluating the model on the testing data are as follows:\n",
        "\n",
        "- **Test Loss**: 0.0777\n",
        "- **Test Accuracy**: 0.9766 (97.66%)\n",
        "\n",
        "Interpretation:\n",
        "- **Test Loss**: The average loss (categorical crossentropy) calculated on the testing data is approximately 0.0777. This indicates how well the model's predictions match the true labels on average. A lower loss value suggests better performance.\n",
        "  \n",
        "- **Test Accuracy**: The accuracy of the model on the testing data is approximately 97.66%. This means that the model correctly classified 97.66% of the testing images into their respective classes. A higher accuracy indicates better performance.\n",
        "\n",
        "Overall, the model performed very well on the unseen testing data, achieving high accuracy and low loss, which suggests that it has learned to generalize effectively from the training data to make accurate predictions on new, unseen images."
      ],
      "metadata": {
        "id": "leD6o5Mu-TIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on the testing data\n",
        "\n",
        "# Testing Data: x_test_flat\n",
        "# x_test_flat: Flattened testing images after normalization\n",
        "\n",
        "# The 'predict' method generates predictions for the testing data using the trained model\n",
        "# It returns the predicted probability distribution for each class for each testing sample\n",
        "y_pred = model.predict(x_test_flat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfNu42U7re2y",
        "outputId": "41fc1c0a-a6a3-4e8f-deaf-a79913b5a859"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQe-hTWgsAVS",
        "outputId": "a70b027f-3022-4111-a3be-3b23eebb44b3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3260939e-06, 1.0490104e-08, 3.2743465e-05, ..., 9.9987388e-01,\n",
              "        1.8458086e-06, 1.9532261e-05],\n",
              "       [1.2957817e-07, 9.8363862e-06, 9.9997574e-01, ..., 4.3122684e-12,\n",
              "        2.2468637e-06, 8.5945953e-14],\n",
              "       [5.4935854e-06, 9.9658543e-01, 8.0584921e-04, ..., 1.6444027e-03,\n",
              "        3.8950267e-04, 2.2102631e-05],\n",
              "       ...,\n",
              "       [3.6375561e-10, 1.0981247e-10, 1.2968375e-10, ..., 2.9031321e-06,\n",
              "        3.1332111e-06, 2.0152076e-05],\n",
              "       [2.3094890e-09, 4.7519128e-10, 7.6320478e-12, ..., 5.2811540e-08,\n",
              "        5.0837748e-06, 5.0765139e-11],\n",
              "       [3.2166458e-06, 2.8291688e-12, 8.2772829e-07, ..., 9.2499142e-12,\n",
              "        2.2854125e-09, 1.0124429e-09]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fInS5qs_sPUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}